This is an entity recognition task, so I preprocessed the dataset accordingly. 
Using the Surrey-NLP/PLOD-CW dataset, I fine-tuned the BERT LLM. 
The preprocessing involved tokenization and annotation alignment. 
Each entity type was carefully tagged to enhance model training.